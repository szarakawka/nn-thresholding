# use python 3

from collections import defaultdict
from scipy.sparse import lil_matrix
import pickle
import os.path
# from dataio.lshtc3_io2 import load_train_data_row_texts_and_labels


def calculate_label_to_doc_mapping(train_data_labels):
    """
    :param train_data_labels: list of list of labels for each document
    :return a dictionary containing mapping from label_id to list of document_ids
    """
    label2art = defaultdict(list)

    for (n, labels) in enumerate(train_data_labels):
        for l in labels:
            label2art[l].append(n)

    return label2art


def normalize_ids(list_of_original_label_ids, first_id=0):
    """
    Used to normalize label ids, so that they are form 0 to nClass-1; or from 1 to nClass (if first_id=1)

    :param list_of_original_label_ids: list of original labels ids of length nClass
    :return: Returns two dictionaries: original_label -> normalized_label and normalized_label -> original_label
    """

    orig2norm = {}
    norm2orig = {}

    for (n, orig_label) in enumerate(sorted(list_of_original_label_ids)):
        orig2norm[orig_label] = n + first_id
        norm2orig[n + first_id] = orig_label

    return orig2norm, norm2orig


def list_of_lists_to_sparse_matrix(normalized_labels_ll, n_labels=None):

    if n_labels is None:
        n_labels = max([item for sublist in normalized_labels_ll for item in sublist]) + 1

    labels_mtx = lil_matrix((len(normalized_labels_ll), n_labels), dtype=bool)
    for (row, cols) in enumerate(normalized_labels_ll):
        for col in cols:
            labels_mtx[row, col] = True
    return labels_mtx.tocsr()



def to_fastText_format(list_of_texts, list_of_labels, destination_file_path):
    """

    :param list_of_texts: List of strings. Each string is a whole document to classify
    :param list_of_labels: List of list of label_ids(ints): for each document a list of labels is given
    :param destination_file_path:
    """

    with open(destination_file_path, 'a') as f:
        for (text, labels) in zip(list_of_texts, list_of_labels):
            labels_fasttext_prefix = ' '.join(['__label__' + str(s) for s in labels])
            f.write(labels_fasttext_prefix + ' ' + text + '\n')



def from_fastText_predictions(file_path):
    """
    Used to obtain python lists that can be then fetched into evaluation methods.

    :param file_path: file generated by command: fasttext predict-prob ... -output file_path
    :return: labelcandidates: list of tuples (one tuple for each testing instance): (labels, probabilities)
    """

    with open(file_path, 'r') as f:
        content = f.readlines()

    content = [line.strip() for line in content]
    return from_fastText_string_predictions(content)


def from_fastText_string_predictions(list_of_strings):
    """
    Used to obtain python lists that can be then fetched into evaluation methods.

    :param list_of_strings: list of strings from the file generated with: fasttext predict-prob ... -output file_path
    :return: labelcandidates: list of tuples (one tuple for each testing instance): (labels, probabilities)

    Example: in = ['__label__123 0.23 __label__43 0.12 __label__5028 0.0012e-7', '__label__88 0.72 __label__33 0.01']
    result = from_fastText_string_predictions(in)
    assert result == [([123, 43, 5028], [0.23, 0.12, 0.0012e-7]), ([88, 33],[0.72, 0.01])]

    """

    result = []
    for line in list_of_strings:
        l = line.split()
        labels = [int(el.replace('__label__', '')) for el in l[::2]]
        probabilities = [float(el) for el in l[1::2]]
        result.append((labels, probabilities))

    return result


def labels_of_test_data_instance_string_fastText_format(line_from_test_file):
    """
    Used to obtain python lists that can be then fetched into evaluation methods as a ground truth.

    :param list_of_strings: one line from test data file (in fastText format)
    :return: labelcandidates: list with ground true labels per instance

    Example: in = '__label__24883 Alfred Habdank Skarbek Korzybski (July 3, 1879   March 1, 1950) was a Polish-American philosopher and scientist. He is most remembered for developing the theory of general semantics.'
    assert labels_of_test_data_instance_string_fastText_format(in) == [24883]

    in = '__label__14655 __label__22235 This article is about the demographic features of the population of American Samoa, including population density, ethnicity, education level, health of the populace, economic status, religious affiliations and other aspects of the population.'
    assert labels_of_test_data_instance_string_fastText_format(in) == [14655, 22235]

    """

    result = []
    for w in line_from_test_file.split():
        if w.startswith('__label__'):
            result.append(int(w.replace('__label__', '')))
        else:
            break

    return result


def labels_of_test_data_from_fastText_format(test_file_path):
    """
    Used to obtain python lists that can be then fetched into evaluation methods as a ground truth.

    :param test_file_path: path to test data file (in fastText format)
    :return: labels: list of lists (one list per test instance) with ground true labels of instances

    """
    with open(test_file_path, 'r') as f:
        content = f.readlines()

    return [labels_of_test_data_instance_string_fastText_format(line.strip()) for line in content]


def load_normalize_labels_and_save(original_dataset_pickled_path_train, normalized_dataset_pickled_path_train=None):
    """
    Normalizes label ids so they start from id=1, saves normalized data, as well as a mapping function from original
    label to normalized one

    :param original_dataset_pickled_path_train:
    :param normalized_dataset_pickled_path_train:
    :return:
    """

    if normalized_dataset_pickled_path_train is None:
        if original_dataset_pickled_path_train.endswith('.pkl'):
            normalized_dataset_pickled_path_train = original_dataset_pickled_path_train.replace('.pkl', '_normalized.pkl')
        else:
            normalized_dataset_pickled_path_train = original_dataset_pickled_path_train + '_normalized.pkl'

    with open(original_dataset_pickled_path_train, 'rb') as f:
        [texts, data_labels] = pickle.load(f)
    label_to_docs = calculate_label_to_doc_mapping(data_labels)
    original_label_ids = label_to_docs.keys()
    orig2norm, norm2orig = normalize_ids(original_label_ids, first_id=1)
    data_normalized_labels = list(map(lambda l: list(map(lambda orig_id: orig2norm[orig_id], l)), data_labels))

    with open(normalized_dataset_pickled_path_train, 'wb') as f:
        pickle.dump([texts, data_normalized_labels], f, protocol=pickle.HIGHEST_PROTOCOL)
    with open(os.path.join(os.path.dirname(normalized_dataset_pickled_path_train), 'orig2normLabelDict.pkl'), 'wb') as f:
        pickle.dump([orig2norm, norm2orig], f, protocol=pickle.HIGHEST_PROTOCOL)




# def give_original_text(example_id_in_fold, in_which_fold, stratification, if_train=True):

 #   example_original_id = from_in_fold_id_to_original_id(example_id_in_fold, in_which_fold, stratification, if_train)

#     data_texts, _ = load_train_data_row_texts_and_labels(
#         "/home/szarak/data/LSHTC3/wikiMediumOriginalLSHTC3/train/pickled_normalized.pkl")

#     return data_texts[example_original_id - 1]


def from_in_fold_id_to_original_id(example_id_in_fold, in_which_fold, stratification, if_train=True):
    if if_train:
        orig_idxs = []
        for n, fold in enumerate(stratification):
            if n != in_which_fold:
                orig_idxs += fold
    else:
        orig_idxs = stratification[in_which_fold]

    return orig_idxs[example_id_in_fold] + 1   # !!!!!!!!!!!! This + 1 is very important!!




